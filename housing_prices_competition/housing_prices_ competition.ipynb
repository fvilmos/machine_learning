{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Melbrn Data estimator mae: 13,289**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helpers\n",
    "USE_LOG = 0\n",
    "def log_data(data):\n",
    "    if USE_LOG == 1:\n",
    "        return np.log(data)\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def delog_data(data):\n",
    "    if USE_LOG == 1:\n",
    "        return np.exp(data)\n",
    "    else:\n",
    "        return data\n",
    "    \n",
    "def substitute_row_log_value(data, name_of_colubn):\n",
    "    data[name_of_colubn] = np.log(data[name_of_colubn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/train.csv')\n",
    "test_data = pd.read_csv('./data/test.csv')\n",
    "\n",
    "#print (\"data columns:\", len(data.columns),len(test_data.columns))\n",
    "price = data['SalePrice']\n",
    "\n",
    "data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "\n",
    "test_data['SalePrice'] = pd.Series(np.random.randn(len(data)-1), index=test_data.index)\n",
    "test_data.dropna(axis=0, subset=['SalePrice'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#corelation\n",
    "corrVal = data.corr()\n",
    "print (corrVal['SalePrice'].sort_values(ascending=True)[0:10])\n",
    "\n",
    "\n",
    "bsmCatCol = ['BsmtCond', 'BsmtQual','BsmtFinType1','BsmtFinType2','BsmtExposure']\n",
    "bsmNumCol = ['BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF']\n",
    "\n",
    "\n",
    "bsm = data[bsmCatCol].copy()\n",
    "tbsm = test_data[bsmCatCol].copy()\n",
    "\n",
    "numbsm = data[bsmNumCol].copy()\n",
    "tnumbsm = test_data[bsmNumCol].copy()\n",
    "\n",
    "print (bsm.head(5))\n",
    "\n",
    "for cl in bsm.columns:\n",
    "    bsm[cl] = bsm[cl].fillna('None')\n",
    "    tbsm[cl] = tbsm[cl].fillna('None')\n",
    "\n",
    "\n",
    "cond_encoder = LabelEncoder()\n",
    "for cl in bsm.columns:\n",
    "    bsm[cl] = cond_encoder.fit_transform(bsm[cl])\n",
    "    tbsm[cl] = cond_encoder.fit_transform(tbsm[cl])\n",
    "\n",
    "cond_encoder = LabelEncoder()\n",
    "for cl in numbsm.columns:\n",
    "    numbsm[cl] = cond_encoder.fit_transform(numbsm[cl])\n",
    "    tnumbsm[cl] = cond_encoder.fit_transform(tnumbsm[cl])\n",
    "    \n",
    "    \n",
    "print(bsm.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Features from FT\n",
    "#################################\n",
    "\n",
    "data['AllSF'] = data['TotalBsmtSF']+ data['1stFlrSF'] + data['2ndFlrSF']\n",
    "test_data['AllSF'] = test_data['TotalBsmtSF']+ test_data['1stFlrSF'] + test_data['2ndFlrSF']\n",
    "\n",
    "data['Baths']=data['BsmtFullBath'] + data['FullBath'] + data['BsmtHalfBath'] + data['HalfBath']\n",
    "test_data['Baths']=test_data['BsmtFullBath'] + test_data['FullBath'] + test_data['BsmtHalfBath'] + test_data['HalfBath']\n",
    "\n",
    "data['YrBltRemodAndGarage']=data['YearBuilt']+data['YearRemodAdd'] +data['GarageYrBlt']\n",
    "test_data['YrBltRemodAndGarage']=test_data['YearBuilt']+test_data['YearRemodAdd'] +test_data['GarageYrBlt']\n",
    "\n",
    "\n",
    "data['Porch']=data['ScreenPorch']+ data['OpenPorchSF']\n",
    "test_data['Porch']=test_data['ScreenPorch'] +  test_data['OpenPorchSF']\n",
    "\n",
    "\n",
    "data['YrConst']=data['YearBuilt'] + data['GarageYrBlt']\n",
    "test_data['YrConst']=test_data['YearBuilt']+test_data['GarageYrBlt']\n",
    "\n",
    "data['GrLivArX']=bsm['BsmtCond']*numbsm['BsmtFinSF1'] + bsm['BsmtQual']*numbsm['BsmtFinSF1']\n",
    "test_data['GrLivArX']=tbsm['BsmtCond']*tnumbsm['BsmtFinSF1'] + tbsm['BsmtQual']*tnumbsm['BsmtFinSF1']\n",
    "\n",
    "\n",
    "y = log_data(data.SalePrice)\n",
    "\n",
    "#====================\n",
    "cols_with_missing = [col for col in data.columns if data[col].isnull().any()]\n",
    "\n",
    "low_cardinality_cols = [cname for cname in data.columns if \n",
    "#                        data[cname].nunique() < 15 and\n",
    "                        data[cname].dtype == \"object\"]\n",
    "numeric_cols = [cname for cname in data.columns if \n",
    "                                data[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "my_cols = low_cardinality_cols + numeric_cols\n",
    "train_predictors = data[my_cols]\n",
    "test_predictors = test_data[my_cols]\n",
    "\n",
    "print (\"after dropping and adding txt:\", len(train_predictors.columns), len(test_predictors.columns))\n",
    "\n",
    "one_hot_encoded_training_predictors = pd.get_dummies(train_predictors)\n",
    "one_hot_encoded_test_predictors = pd.get_dummies(test_predictors)\n",
    "\n",
    "final_train, final_test = one_hot_encoded_training_predictors.align(one_hot_encoded_test_predictors,\n",
    "                                                                    join='left', \n",
    "                                                                    axis=1)\n",
    "#use it\n",
    "X = final_train\n",
    "tX = final_test\n",
    "\n",
    "X = final_train.drop(['SalePrice'], axis=1).select_dtypes(exclude=['object'])\n",
    "tX = final_test.drop(['SalePrice'], axis=1).select_dtypes(exclude=['object'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#ax = sns.boxplot(x=X[\"MSSubClass\"])\n",
    "USE_PLOT = 1\n",
    "\n",
    "if USE_PLOT==1:\n",
    "    fig = plt.figure(figsize=(17, 235))\n",
    "\n",
    "    for i,c in zip(range(0,50),final_train.columns):\n",
    "        fig.add_subplot(150,2, i+1)\n",
    "        sns.boxplot(y=final_train.iloc[:,i])\n",
    "        sns.regplot(final_train[c], price)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#==============\n",
    "# split dataset to train and test datasets\n",
    "train_X, test_X, train_y, test_y = train_test_split(X.values, y.values, test_size=0.17,random_state=23)\n",
    "\n",
    "# most_frequent, mean,median\n",
    "# use inputter to replace missing values\n",
    "my_imputer = SimpleImputer(strategy='median')\n",
    "train_X = my_imputer.fit_transform(train_X)\n",
    "test_X = my_imputer.transform(test_X)\n",
    "\n",
    "tX = my_imputer.transform(tX)\n",
    "\n",
    "print (\"columns: \", train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature elimination\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "alldata = pd.concat([data.copy(),test_data.copy()])\n",
    "ay = alldata.SalePrice\n",
    "\n",
    "falldata = alldata.drop(['SalePrice'], axis=1).select_dtypes(exclude=['object'])\n",
    "\n",
    "\n",
    "falldata.shape\n",
    "print(falldata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean data\n",
    "cfalldata = falldata.copy()\n",
    "\n",
    "for cl in cfalldata.columns:\n",
    "    print(cl,cfalldata[cl].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handele nans\n",
    "cfalldata['LotFrontage'] = cfalldata['LotFrontage'].fillna(0)\n",
    "cfalldata['MasVnrArea'] = cfalldata['MasVnrArea'].fillna(0)\n",
    "cfalldata['GarageYrBlt'] = cfalldata['GarageYrBlt'].fillna(cfalldata['GarageYrBlt'].median())\n",
    "cfalldata['YrBltRemodAndGarage'] = cfalldata['YrBltRemodAndGarage'].fillna(cfalldata['YrBltRemodAndGarage'].median())\n",
    "cfalldata['YrConst'] = cfalldata['YrConst'].fillna(cfalldata['YrConst'].median())\n",
    "\n",
    "\n",
    "for cl in cfalldata.columns:\n",
    "    if cfalldata[cl].isna().sum() >0:\n",
    "        cfalldata[cl] = cfalldata[cl].fillna(cfalldata['YrConst'].median())\n",
    "\n",
    "\n",
    "print(cfalldata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "\n",
    "falldata = cfalldata.copy()\n",
    "print (falldata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle categorical values\n",
    "catalldata = alldata.select_dtypes(include=['object'])\n",
    "\n",
    "print (catalldata.columns,catalldata.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in catalldata.columns:\n",
    "    print(cl,catalldata[cl].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle missing values\n",
    "for cl in catalldata.columns:\n",
    "    print(cl,catalldata[cl].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform to umeric\n",
    "for cl in catalldata.columns:\n",
    "    catalldata[cl] = catalldata[cl].fillna('None')\n",
    "\n",
    "cond_encoder = LabelEncoder()\n",
    "for cl in catalldata.columns:\n",
    "    catalldata[cl] = cond_encoder.fit_transform(catalldata[cl])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in catalldata.columns:\n",
    "    print(cl,catalldata[cl].unique())\n",
    "    \n",
    "print(catalldata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(falldata.shape, catalldata.shape, type(falldata),type(catalldata))\n",
    "\n",
    "fcatalldata = pd.concat([falldata, catalldata],axis=1)\n",
    "\n",
    "print(fcatalldata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# craft new data\n",
    "\n",
    "cdata = fcatalldata.copy()\n",
    "\n",
    "cdata['AllSF'] = cdata['TotalBsmtSF']+ cdata['1stFlrSF'] + cdata['2ndFlrSF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iddata = cdata['Id']+1460\n",
    "cdata = cdata.drop(columns=['Id'])\n",
    "\n",
    "xcdata = cdata[:1460]\n",
    "xval = cdata[:1459]\n",
    "\n",
    "xay = ay[:1460]\n",
    "\n",
    "print(xcdata.shape,xcdata.shape, ay.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "tr_X, te_X, tr_y, te_y = train_test_split(xcdata.values, xay.values, test_size=0.17,random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "params = {'n_estimators': 1000, \n",
    "          'max_depth': 4, \n",
    "          'min_samples_split': 2,\n",
    "          'learning_rate': 0.05, \n",
    "          'loss': 'ls',\n",
    "          'alpha':0.9,\n",
    "          'random_state':0,\n",
    "          'subsample': 0.8,\n",
    "          'tol':0.0001, \n",
    "          'min_samples_leaf':3,\n",
    "          'validation_fraction':0.1,\n",
    "          'criterion':'friedman_mse',\n",
    "          'max_features':0.3\n",
    "         }\n",
    "\n",
    "n_jobs=5\n",
    "\n",
    "clf = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "clf.fit(tr_X, tr_y)\n",
    "\n",
    "sc = clf.score(tr_X,tr_y)\n",
    "mse = mean_squared_error(te_y, clf.predict(te_X))\n",
    "\n",
    "print(\"-------------------\")\n",
    "print(\"secound approach\")\n",
    "print(\"MSE: %.4f\" % mse)\n",
    "\n",
    "val_predictionsx = clf.predict(te_X)\n",
    "val_mae = mean_absolute_error(te_y,val_predictionsx)\n",
    "print(\"mae: {:,.0f}\".format(val_mae))\n",
    "print(\"score:\", sc)\n",
    "print ('min:',int(np.min(val_predictionsx)),'max:',int(np.max(val_predictionsx)) )\n",
    "print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iddata.shape,xval.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_OUT_NEW = 0\n",
    "\n",
    "if USE_OUT_NEW == 1:\n",
    "    val_predictionsxx = clf.predict(xval)\n",
    "\n",
    "    output = pd.DataFrame({'Id': iddata[:1459], 'SalePrice': val_predictionsxx})\n",
    "    output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "for nr in range(0,1):\n",
    "    params = {'n_estimators': 10000, \n",
    "              'max_depth': 4, \n",
    "              'min_samples_split': 2,\n",
    "              'learning_rate': 0.05, \n",
    "              'loss': 'ls',\n",
    "              'alpha':0.9,\n",
    "              'random_state':36,\n",
    "              'subsample': 0.8,\n",
    "              'tol':0.0001, \n",
    "              'min_samples_leaf':3,\n",
    "              'validation_fraction':0.1,\n",
    "              'criterion':'friedman_mse',\n",
    "              'max_features':0.3\n",
    "             }\n",
    "\n",
    "    n_jobs=5\n",
    "\n",
    "    clf = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "    clf.fit(train_X, train_y)\n",
    "\n",
    "    sc = clf.score(train_X,train_y)\n",
    "    mse = mean_squared_error(test_y, clf.predict(test_X))\n",
    "\n",
    "    print(\"-------------------\")\n",
    "    print(\"first approach\")\n",
    "    print(\"MSE: %.4f\" % mse)\n",
    "\n",
    "    val_predictions = clf.predict(test_X)\n",
    "    val_mae = mean_absolute_error(delog_data(test_y),delog_data(val_predictions))\n",
    "    print(\"mae: {:,.0f}\".format(val_mae))\n",
    "    print(\"score:\", sc)\n",
    "    print ('min:',int(np.min(val_predictions)),'max:',int(np.max(val_predictions)) )\n",
    "    print(\"-------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_OUT = 1\n",
    "\n",
    "if USE_OUT == 1:\n",
    "    val_predictions = clf.predict(tX)\n",
    "\n",
    "    for val in range(0,5):\n",
    "        print(\"Id:\", test_data.Id[val],\"SalePrice:\", y[val], \"SalePricePred:\",val_predictions[val])\n",
    "\n",
    "    output = pd.DataFrame({'Id': test_data.Id,'SalePrice': delog_data(val_predictions)})\n",
    "    output.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
